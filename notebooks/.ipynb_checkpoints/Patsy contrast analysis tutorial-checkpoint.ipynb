{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patsy contrast tutorial\n",
    "\n",
    "The following tutorial fro the patsy package is based on Schad, Vasishth, Hohenstein, and Kliegl (2020), Tutorial of contrast coding for analysis specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for conducting the tutorial\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The General issue\n",
    "\n",
    "The data produced from experimental designs are often analysed using some variant of the analysis of variance (ANOVA) depnding on the experimental design. Standard practive is analsye the data with the desired ANOVA check the F-test for significance followed by Post hoc analysis of all the differences with some form pairwise comparison (Bonferroni, typically). This apporaoch is limited though if researchers have a prior theory driven comparison hypotheses before seeing the data.\n",
    "\n",
    "The tutorial below focuses on Frequentist statistics but its application in the following notebooks is of course Bayesian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>F</th>\n",
       "      <th>DV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>F1</td>\n",
       "      <td>1.124869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>F1</td>\n",
       "      <td>0.677649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>F1</td>\n",
       "      <td>0.694366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>F1</td>\n",
       "      <td>0.585406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>F1</td>\n",
       "      <td>0.973082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>F2</td>\n",
       "      <td>-0.060308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>F2</td>\n",
       "      <td>0.748962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>F2</td>\n",
       "      <td>0.247759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>F2</td>\n",
       "      <td>0.463808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>F2</td>\n",
       "      <td>0.350126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject   F        DV\n",
       "0        1  F1  1.124869\n",
       "1        2  F1  0.677649\n",
       "2        3  F1  0.694366\n",
       "3        4  F1  0.585406\n",
       "4        5  F1  0.973082\n",
       "5        1  F2 -0.060308\n",
       "6        2  F2  0.748962\n",
       "7        3  F2  0.247759\n",
       "8        4  F2  0.463808\n",
       "9        5  F2  0.350126"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate data for two groups\n",
    "np.random.seed(1)\n",
    "F1 = np.random.normal(0.8,0.2,5)\n",
    "F2 = np.random.normal(0.4,0.2,5)\n",
    "n = 5\n",
    "\n",
    "data = {'Subject': range(n),\n",
    "        'F1': F1,\n",
    "         'F2': F2\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame (data, columns = ['Subject','F1','F2'])\n",
    "df =pd.melt(df,id_vars=['Subject'],var_name='F', value_name='DV')\n",
    "df[\"Subject\"] = df[\"Subject\"] + 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     DV   R-squared:                       0.488\n",
      "Model:                            OLS   Adj. R-squared:                  0.424\n",
      "Method:                 Least Squares   F-statistic:                     7.618\n",
      "Date:                Thu, 19 Nov 2020   Prob (F-statistic):             0.0247\n",
      "Time:                        13:01:08   Log-Likelihood:                0.24060\n",
      "No. Observations:                  10   AIC:                             3.519\n",
      "Df Residuals:                       8   BIC:                             4.124\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.8111      0.118      6.867      0.000       0.539       1.083\n",
      "F[T.F2]       -0.4610      0.167     -2.760      0.025      -0.846      -0.076\n",
      "==============================================================================\n",
      "Omnibus:                        0.097   Durbin-Watson:                   2.967\n",
      "Prob(Omnibus):                  0.952   Jarque-Bera (JB):                0.310\n",
      "Skew:                           0.110   Prob(JB):                        0.856\n",
      "Kurtosis:                       2.166   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harri\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1450: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    }
   ],
   "source": [
    "mod = ols(\"DV ~ F\", data=df)\n",
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## $$ Intercept (F1) = \\hat{\\mu}_1 = 0.81$$\n",
    "## $$ Slope (F2) = \\hat{\\mu}_1 - \\hat{\\mu}_2 = -0.46$$\n",
    "\n",
    "When using Treatment coding the mean of baseline/control group is the intercept of the ouptut and the Slope (Beta) is the diffence between the two groups, please note that tis was all generated by defaukt in the OLS function, so if not specifying the exact cotrasts be careful with interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genral linear model formulation\n",
    "\n",
    "Why these regression coeffiecnt are produced "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treatment Contrasts\n",
    "The default contrast in many ststisticsl softwars is the treatment contrast. This type of statisical model contrast name i derived from its general use in medical settings, where treatments are compared to a baseline (control group). (insert example here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 26.24345364,   3.88243586,   4.71828248,  -0.72968622,\n",
       "        18.65407629, -13.01538697,  27.44811764,   2.38793099,\n",
       "        13.19039096,   7.50629625])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum contrats\n",
    "\n",
    "This type of test contrast is different from the treatment contrasts, as the diffence is generated by comparing eaxch facors mean against the grand mean of all the levels of the factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(1, 5)\n"
     ]
    }
   ],
   "source": [
    "print(range(1,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated Contrasts\n",
    "\n",
    "This contrast compares groups in succesive order. i.e if you had groups separated by some level of manipulation with settings of low, medium and high; low would be compared to medium and then medium compared to high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations\n",
    "\n",
    "Schad, D. J., Vasishth, S., Hohenstein, S., & Kliegl, R. (2020). How to capitalize on a priori contrasts in linear (mixed) models: A tutorial. Journal of Memory and Language, 110, 104038."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
